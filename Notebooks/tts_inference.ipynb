{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uganda-lang/Ganda-TTS/blob/main/Notebooks/tts_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:29:06.456794Z",
          "iopub.status.busy": "2025-07-03T17:29:06.456583Z",
          "iopub.status.idle": "2025-07-03T17:30:52.109119Z",
          "shell.execute_reply": "2025-07-03T17:30:52.108432Z",
          "shell.execute_reply.started": "2025-07-03T17:29:06.456774Z"
        },
        "id": "SlRz9NJMyFHR",
        "scrolled": true,
        "trusted": true,
        "outputId": "f36c9866-3dba-4e63-e2e4-7dcc9e69c306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/72.9 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth 2025.6.12 requires bitsandbytes, which is not installed.\n",
            "unsloth 2025.6.12 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9, which is not installed.\n",
            "unsloth 2025.6.12 requires tyro, which is not installed.\n",
            "unsloth 2025.6.12 requires unsloth_zoo>=2025.6.8, which is not installed.\n",
            "unsloth 2025.6.12 requires xformers>=0.0.27.post2, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo -q\n",
        "!pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer -q\n",
        "!pip install --no-deps unsloth -q\n",
        "!pip install transformers==4.52.3 -q\n",
        "!pip install snac -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "execution": {
          "iopub.execute_input": "2025-07-03T17:30:52.111826Z",
          "iopub.status.busy": "2025-07-03T17:30:52.111099Z",
          "iopub.status.idle": "2025-07-03T17:31:30.250980Z",
          "shell.execute_reply": "2025-07-03T17:31:30.250405Z",
          "shell.execute_reply.started": "2025-07-03T17:30:52.111793Z"
        },
        "id": "WoXgKtIuvmGg",
        "outputId": "5dda01e3-a4fc-4a8e-f093-199171cd595b",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bitsandbytes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2326476179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Try loading bitsandbytes and triton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mbitsandbytes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mcdequantize_blockwise_fp32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdequantize_blockwise_fp32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bitsandbytes'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:31:30.252118Z",
          "iopub.status.busy": "2025-07-03T17:31:30.251621Z",
          "iopub.status.idle": "2025-07-03T17:32:37.630531Z",
          "shell.execute_reply": "2025-07-03T17:32:37.629700Z",
          "shell.execute_reply.started": "2025-07-03T17:31:30.252098Z"
        },
        "id": "tCGXyGfr0UHh",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Uganda-lang/Orpheous-Eng-multi-speaker\",\n",
        "    max_seq_length= 2048, # Choose any for long context!\n",
        "    dtype = None, # Select None for auto detection\n",
        "    load_in_4bit = True, # Select True for 4bit which reduces memory usage\n",
        "    token = \"[token]\", # Replace with your token\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:32:37.631578Z",
          "iopub.status.busy": "2025-07-03T17:32:37.631307Z",
          "iopub.status.idle": "2025-07-03T17:32:39.301959Z",
          "shell.execute_reply": "2025-07-03T17:32:39.301274Z",
          "shell.execute_reply.started": "2025-07-03T17:32:37.631551Z"
        },
        "id": "NX6o-V0f1aET",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from snac import SNAC\n",
        "\n",
        "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\",\n",
        "                                  token=\"[token]\")\n",
        "snac_model = snac_model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:32:39.307002Z",
          "iopub.status.busy": "2025-07-03T17:32:39.306769Z",
          "iopub.status.idle": "2025-07-03T17:32:39.332125Z",
          "shell.execute_reply": "2025-07-03T17:32:39.329920Z",
          "shell.execute_reply.started": "2025-07-03T17:32:39.306981Z"
        },
        "id": "eYdWk82J2ylJ",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# Moving snac_model cuda to cpu\n",
        "snac_model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:32:39.333619Z",
          "iopub.status.busy": "2025-07-03T17:32:39.333375Z",
          "iopub.status.idle": "2025-07-03T17:32:39.352806Z",
          "shell.execute_reply": "2025-07-03T17:32:39.352031Z",
          "shell.execute_reply.started": "2025-07-03T17:32:39.333597Z"
        },
        "id": "VfdwLfJswAOu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "def generate_audio_from_prompt(\n",
        "    prompt: str,\n",
        "    chosen_voice: str,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    snac_model,\n",
        "    display_result: bool = True\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Generates audio from a text prompt, with explicit memory cleanup steps.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The text prompt to generate audio for.\n",
        "        chosen_voice (str): The voice to use for the prompt (e.g., \"en_speaker_0\").\n",
        "        model: The pre-loaded main language model.\n",
        "        tokenizer: The pre-loaded tokenizer for the language model.\n",
        "        snac_model: The pre-loaded SNAC audio model.\n",
        "        display_result (bool): If True, prints the prompt and displays an audio player.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The generated audio waveform as a PyTorch tensor on the CPU.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Helper function for audio decoding ---\n",
        "    def redistribute_codes(code_list, device):\n",
        "        \"\"\"Restructures flat code list and places tensors on the correct device.\"\"\"\n",
        "        layer_1, layer_2, layer_3 = [], [], []\n",
        "        for i in range(len(code_list) // 7):\n",
        "            base_idx = 7 * i\n",
        "            layer_1.append(code_list[base_idx])\n",
        "            layer_2.append(code_list[base_idx + 1] - 4096)\n",
        "            layer_3.append(code_list[base_idx + 2] - (2 * 4096))\n",
        "            layer_3.append(code_list[base_idx + 3] - (3 * 4096))\n",
        "            layer_2.append(code_list[base_idx + 4] - (4 * 4096))\n",
        "            layer_3.append(code_list[base_idx + 5] - (5 * 4096))\n",
        "            layer_3.append(code_list[base_idx + 6] - (6 * 4096))\n",
        "\n",
        "        # Create the tensors directly on the target device.\n",
        "        codes = [\n",
        "            torch.tensor(layer_1, device=device, dtype=torch.long).unsqueeze(0),\n",
        "            torch.tensor(layer_2, device=device, dtype=torch.long).unsqueeze(0),\n",
        "            torch.tensor(layer_3, device=device, dtype=torch.long).unsqueeze(0)\n",
        "        ]\n",
        "\n",
        "        # Now, `codes` are on the GPU, matching the `snac_model`.\n",
        "        audio_hat = snac_model.decode(codes)\n",
        "        return audio_hat\n",
        "\n",
        "\n",
        "    device = model.device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 1. Format and tokenize prompt\n",
        "        formatted_prompt = f\"{chosen_voice}: {prompt}\" if chosen_voice else prompt\n",
        "        input_ids = tokenizer(formatted_prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "        start_token = torch.tensor([[128259]], dtype=torch.int64)\n",
        "        end_tokens = torch.tensor([[128009, 128260]], dtype=torch.int64)\n",
        "        modified_input_ids = torch.cat([start_token, input_ids, end_tokens], dim=1)\n",
        "\n",
        "        # 2. Generate token IDs with the language model\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=modified_input_ids.to(device),\n",
        "            max_new_tokens=2048,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.95,\n",
        "            repetition_penalty=1.1,\n",
        "            num_return_sequences=1,\n",
        "            eos_token_id=128258,\n",
        "            use_cache=True\n",
        "        )\n",
        "\n",
        "        # 3. Post-process tokens\n",
        "        token_to_find = 128257\n",
        "        token_to_remove = 128258\n",
        "\n",
        "        token_indices = (generated_ids == token_to_find).nonzero(as_tuple=True)\n",
        "        if len(token_indices[1]) > 0:\n",
        "            last_occurrence_idx = token_indices[1][-1].item()\n",
        "            cropped_tensor = generated_ids[:, last_occurrence_idx + 1:]\n",
        "        else:\n",
        "            cropped_tensor = generated_ids\n",
        "\n",
        "        processed_tensor = cropped_tensor[cropped_tensor != token_to_remove]\n",
        "\n",
        "        row_length = processed_tensor.size(0)\n",
        "        new_length = (row_length // 7) * 7\n",
        "        trimmed_tensor = processed_tensor[:new_length]\n",
        "\n",
        "        code_list = [t.item() - 128266 for t in trimmed_tensor.cpu()]\n",
        "\n",
        "        # 4. Decode codes into an audio waveform\n",
        "        samples_gpu = redistribute_codes(code_list, device=device)\n",
        "\n",
        "        # Move the final result to CPU before returning\n",
        "        samples_cpu = samples_gpu.squeeze().cpu()\n",
        "\n",
        "    # Explicitly delete large intermediate tensors\n",
        "    del generated_ids\n",
        "    del cropped_tensor\n",
        "    del processed_tensor\n",
        "    del trimmed_tensor\n",
        "    del code_list\n",
        "    del samples_gpu\n",
        "    if 'modified_input_ids' in locals(): del modified_input_ids\n",
        "\n",
        "    # Force garbage collection and empty CUDA cache\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # 5. Display and return the result\n",
        "    if display_result:\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        display(Audio(samples_cpu.numpy(), rate=24000))\n",
        "\n",
        "    return samples_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:08:21.574094Z",
          "iopub.status.busy": "2025-07-03T17:08:21.573819Z",
          "iopub.status.idle": "2025-07-03T17:08:41.979735Z",
          "shell.execute_reply": "2025-07-03T17:08:41.979008Z",
          "shell.execute_reply.started": "2025-07-03T17:08:21.574075Z"
        },
        "id": "ukI47BMcwAL8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Hello I can speak in English as christopher, one of the voices I can speak.\"\n",
        "my_voice = \"christopher\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generated_audio_tensor = generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "Ga64eHr2qdbX"
      },
      "outputs": [],
      "source": [
        "# Supported voices:\n",
        "# 'Barbara',\n",
        "# 'Mary',\n",
        "#  'Jennifer'\n",
        "#  'Jessica'\n",
        "#  'Susan'\n",
        "#  'James'\n",
        "#  'Linda'\n",
        "#  'Patricia'\n",
        "#  'Elizabeth'\n",
        "#  'Christopher'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-01T21:28:43.832471Z",
          "iopub.status.busy": "2025-07-01T21:28:43.831582Z",
          "iopub.status.idle": "2025-07-01T21:29:18.794829Z",
          "shell.execute_reply": "2025-07-01T21:29:18.793961Z",
          "shell.execute_reply.started": "2025-07-01T21:28:43.832442Z"
        },
        "id": "d-Ze4aZjxgaU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Or as barbra, this is one of my female voices. Pretty cool right?.\"\n",
        "my_voice = \"barbara\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-01T21:31:36.433934Z",
          "iopub.status.busy": "2025-07-01T21:31:36.433171Z",
          "iopub.status.idle": "2025-07-01T21:31:58.747266Z",
          "shell.execute_reply": "2025-07-01T21:31:58.746183Z",
          "shell.execute_reply.started": "2025-07-01T21:31:36.433909Z"
        },
        "id": "oIWgx772wAJI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "my_prompt = \"I can also speak as Mary as well.\"\n",
        "my_voice = \"mary\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-01T21:34:49.673835Z",
          "iopub.status.busy": "2025-07-01T21:34:49.673235Z",
          "iopub.status.idle": "2025-07-01T21:35:05.482111Z",
          "shell.execute_reply": "2025-07-01T21:35:05.481188Z",
          "shell.execute_reply.started": "2025-07-01T21:34:49.673798Z"
        },
        "id": "IZ3YkV8LwAGV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Or I can speak as james as you can see.\"\n",
        "my_voice = \"James\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-01T21:35:19.418467Z",
          "iopub.status.busy": "2025-07-01T21:35:19.417839Z",
          "iopub.status.idle": "2025-07-01T21:36:22.796189Z",
          "shell.execute_reply": "2025-07-01T21:36:22.795470Z",
          "shell.execute_reply.started": "2025-07-01T21:35:19.418440Z"
        },
        "id": "ie45Hrg5wADa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "my_prompt = \"This is my other voice called jessica, I have more voices of jennifer, suzan, linda, patricia and elizabeth. But I will be sharing these voices once I am fully done from baking.\"\n",
        "my_voice = \"jessica\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuymkP40wAAa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhIqP8XI31xV"
      },
      "outputs": [],
      "source": [
        "# export model to gguf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1jb1a9DqdbX"
      },
      "source": [
        "# Luganda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T18:15:16.637563Z",
          "iopub.status.busy": "2025-07-03T18:15:16.636546Z",
          "iopub.status.idle": "2025-07-03T18:16:08.662628Z",
          "shell.execute_reply": "2025-07-03T18:16:08.662021Z",
          "shell.execute_reply.started": "2025-07-03T18:15:16.637528Z"
        },
        "id": "RaiNs7aJ3423",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Uganda-lang/Orpheous-Multi-speaker-Lug\",\n",
        "    max_seq_length= 2048, # Choose any for long context!\n",
        "    dtype = None, # Select None for auto detection\n",
        "    load_in_4bit = True, # Select True for 4bit which reduces memory usage\n",
        "    token = \"[token]\", # Replace with your token\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvcvIaAWqdbX"
      },
      "source": [
        "<!-- [('Charles', 3259),\n",
        " ('Sandra', 2314),\n",
        " ('Christopher', 1255),\n",
        " ('Mark', 1123),\n",
        " ('Barbara', 1114),\n",
        " ('Michelle', 1080),\n",
        " ('Karen', 1027),\n",
        " ('James', 925),\n",
        " ('Margaret', 879),\n",
        " ('Daniel', 767)] -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "8qt0yiCjqdbX"
      },
      "outputs": [],
      "source": [
        "# Supported voices:\n",
        "# Charles\n",
        "# Sandra\n",
        "# Christopher\n",
        "# Mark\n",
        "# Barbara\n",
        "# Michelle\n",
        "# Karen\n",
        "# James\n",
        "# Margaret\n",
        "# Daniel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-01T21:52:48.628709Z",
          "iopub.status.busy": "2025-07-01T21:52:48.628360Z",
          "iopub.status.idle": "2025-07-01T21:53:08.920222Z",
          "shell.execute_reply": "2025-07-01T21:53:08.919417Z",
          "shell.execute_reply.started": "2025-07-01T21:52:48.628686Z"
        },
        "trusted": true,
        "id": "VyRxyhQJqdbX"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Nsobolla okwo'geranga Christopher nga wowulila kati.\"\n",
        "my_voice = \"christopher\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-01T21:53:45.334548Z",
          "iopub.status.busy": "2025-07-01T21:53:45.333827Z",
          "iopub.status.idle": "2025-07-01T21:54:03.886449Z",
          "shell.execute_reply": "2025-07-01T21:54:03.885549Z",
          "shell.execute_reply.started": "2025-07-01T21:53:45.334522Z"
        },
        "trusted": true,
        "id": "-uvAA68pqdbX"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Oba neenjogela nga charles wenti.\"\n",
        "my_voice = \"charles\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:34:18.301244Z",
          "iopub.status.busy": "2025-07-03T17:34:18.300536Z",
          "iopub.status.idle": "2025-07-03T17:34:30.455737Z",
          "shell.execute_reply": "2025-07-03T17:34:30.455066Z",
          "shell.execute_reply.started": "2025-07-03T17:34:18.301192Z"
        },
        "trusted": true,
        "id": "qTmOlQasqdbX"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Nina neddoboozi lya Sandra bweliti.\"\n",
        "my_voice = \"sandra\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T06:45:47.420887Z",
          "iopub.status.busy": "2025-07-02T06:45:47.420617Z",
          "iopub.status.idle": "2025-07-02T06:46:02.682336Z",
          "shell.execute_reply": "2025-07-02T06:46:02.681597Z",
          "shell.execute_reply.started": "2025-07-02T06:45:47.420869Z"
        },
        "trusted": true,
        "id": "J7PtCIl7qdbX"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Nsobolla ogwogella bwenti mulino eddoboozi.\"\n",
        "my_voice = \"michelle\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T06:46:17.624215Z",
          "iopub.status.busy": "2025-07-02T06:46:17.623944Z",
          "iopub.status.idle": "2025-07-02T06:46:31.064077Z",
          "shell.execute_reply": "2025-07-02T06:46:31.063294Z",
          "shell.execute_reply.started": "2025-07-02T06:46:17.624194Z"
        },
        "trusted": true,
        "id": "NjX0DXc0qdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Oba nemulino elye'kisajja nga woowulira.\"\n",
        "my_voice = \"daniel\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T06:52:02.280853Z",
          "iopub.status.busy": "2025-07-02T06:52:02.280302Z",
          "iopub.status.idle": "2025-07-02T06:52:27.979285Z",
          "shell.execute_reply": "2025-07-02T06:52:27.978462Z",
          "shell.execute_reply.started": "2025-07-02T06:52:02.280831Z"
        },
        "trusted": true,
        "id": "7fdkKrnbqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Ninna amaloboozi amalala naye nja kugalaga nga mazze oku tureyininga.\"\n",
        "my_voice = \"mark\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T18:17:12.328529Z",
          "iopub.status.busy": "2025-07-03T18:17:12.327791Z",
          "iopub.status.idle": "2025-07-03T18:17:25.118307Z",
          "shell.execute_reply": "2025-07-03T18:17:25.117597Z",
          "shell.execute_reply.started": "2025-07-03T18:17:12.328506Z"
        },
        "trusted": true,
        "id": "oTLuzRuGqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Charlissi yimilila awo.\"\n",
        "my_voice = \"margaret\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jIU6VcuqdbY"
      },
      "source": [
        "# Acholi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T07:05:07.159090Z",
          "iopub.status.busy": "2025-07-02T07:05:07.158469Z",
          "iopub.status.idle": "2025-07-02T07:06:01.759442Z",
          "shell.execute_reply": "2025-07-02T07:06:01.758881Z",
          "shell.execute_reply.started": "2025-07-02T07:05:07.159067Z"
        },
        "trusted": true,
        "id": "JKx_kyxRqdbY"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Uganda-lang/Orpheous-Ach-Multi-speaker\",\n",
        "    max_seq_length= 2048, # Choose any for long context!\n",
        "    dtype = None, # Select None for auto detection\n",
        "    load_in_4bit = True, # Select True for 4bit which reduces memory usage\n",
        "    token = \"[token]\", # Replace with your token\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "9KQLOizoqdbY"
      },
      "outputs": [],
      "source": [
        "# Supported voices:\n",
        "# James\n",
        "# Barbara\n",
        "# Mitchelle\n",
        "# Mark\n",
        "# Christopher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T07:46:36.865163Z",
          "iopub.status.busy": "2025-07-02T07:46:36.864874Z",
          "iopub.status.idle": "2025-07-02T07:46:52.140786Z",
          "shell.execute_reply": "2025-07-02T07:46:52.140047Z",
          "shell.execute_reply.started": "2025-07-02T07:46:36.865144Z"
        },
        "trusted": true,
        "id": "Kvf8P3yEqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Uganda tye ka keme ki lok me pur.\"\n",
        "my_voice = \"mark\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T07:56:39.323649Z",
          "iopub.status.busy": "2025-07-02T07:56:39.323335Z",
          "iopub.status.idle": "2025-07-02T07:57:04.247004Z",
          "shell.execute_reply": "2025-07-02T07:57:04.246263Z",
          "shell.execute_reply.started": "2025-07-02T07:56:39.323629Z"
        },
        "trusted": true,
        "id": "dR5OjkQYqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Lupur twero nongo kony ma dit ka gunongo ngec me gengo onyo cango two ma balo jami ma i poto.\"\n",
        "my_voice = \"barbara\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:00:02.323337Z",
          "iopub.status.busy": "2025-07-02T08:00:02.322717Z",
          "iopub.status.idle": "2025-07-02T08:00:32.156855Z",
          "shell.execute_reply": "2025-07-02T08:00:32.155736Z",
          "shell.execute_reply.started": "2025-07-02T08:00:02.323316Z"
        },
        "trusted": true,
        "id": "0m8j7rG3qdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Ler ma pe gidodo ma woto ka yenyo cam i dye poto obalo cam weng ma tye i poto.\"\n",
        "my_voice = \"james\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:07:25.256657Z",
          "iopub.status.busy": "2025-07-02T08:07:25.256341Z",
          "iopub.status.idle": "2025-07-02T08:07:52.729775Z",
          "shell.execute_reply": "2025-07-02T08:07:52.728929Z",
          "shell.execute_reply.started": "2025-07-02T08:07:25.256636Z"
        },
        "trusted": true,
        "id": "4zgOM28ZqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Gum madwong me timo biacara tye i te yub ma pe jenge i kom gamente.\"\n",
        "my_voice = \"mitchelle\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "E1ZFw7BqqdbY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5V72MItqdbY"
      },
      "source": [
        "# Runkyankole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:11:46.551279Z",
          "iopub.status.busy": "2025-07-02T08:11:46.550570Z",
          "iopub.status.idle": "2025-07-02T08:12:45.398221Z",
          "shell.execute_reply": "2025-07-02T08:12:45.397583Z",
          "shell.execute_reply.started": "2025-07-02T08:11:46.551257Z"
        },
        "trusted": true,
        "id": "Cke1t3-CqdbY"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Uganda-lang/Orpheus-nyn-multi-speaker\",\n",
        "    max_seq_length= 2048, # Choose any for long context!\n",
        "    dtype = None, # Select None for auto detection\n",
        "    load_in_4bit = True, # Select True for 4bit which reduces memory usage\n",
        "    token = \"[token]\", # Replace with your token\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:13:05.691752Z",
          "iopub.status.busy": "2025-07-02T08:13:05.691478Z",
          "iopub.status.idle": "2025-07-02T08:13:20.659357Z",
          "shell.execute_reply": "2025-07-02T08:13:20.658654Z",
          "shell.execute_reply.started": "2025-07-02T08:13:05.691734Z"
        },
        "trusted": true,
        "id": "5CAgbYAqqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Nimbasa kugamba nka Christopher omwiraka eri.\"\n",
        "my_voice = \"christopher\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "GvBN3Hy4qdbY"
      },
      "outputs": [],
      "source": [
        "# Supported voices:\n",
        "\n",
        "# Michelle\n",
        "# James\n",
        "# Patricia\n",
        "# Mark\n",
        "# Elizabeth\n",
        "# Charles\n",
        "# Daniel\n",
        "# Barbara\n",
        "# Christopher\n",
        "# Linda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:16:06.368382Z",
          "iopub.status.busy": "2025-07-02T08:16:06.367861Z",
          "iopub.status.idle": "2025-07-02T08:16:17.537328Z",
          "shell.execute_reply": "2025-07-02T08:16:17.536591Z",
          "shell.execute_reply.started": "2025-07-02T08:16:06.368356Z"
        },
        "trusted": true,
        "id": "V2d5qUGaqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Nimbasa kugamba nka Michelle omwiraka eri.\"\n",
        "my_voice = \"michelle\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:18:50.582226Z",
          "iopub.status.busy": "2025-07-02T08:18:50.581677Z",
          "iopub.status.idle": "2025-07-02T08:19:07.828768Z",
          "shell.execute_reply": "2025-07-02T08:19:07.828085Z",
          "shell.execute_reply.started": "2025-07-02T08:18:50.582208Z"
        },
        "trusted": true,
        "id": "Pp6CykxUqdbY"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Uganda eteire amaani aha buhingi n'oburiisa.\"\n",
        "my_voice = \"james\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:20:21.181153Z",
          "iopub.status.busy": "2025-07-02T08:20:21.180397Z",
          "iopub.status.idle": "2025-07-02T08:20:47.001036Z",
          "shell.execute_reply": "2025-07-02T08:20:47.000296Z",
          "shell.execute_reply.started": "2025-07-02T08:20:21.181129Z"
        },
        "trusted": true,
        "id": "OjjfrbhoqdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Bimwe ebirikugambwa aha reediyo nibihwera abantu kumanya obutare burungi bw'amasharuura gaabo.\"\n",
        "my_voice = \"patricia\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:22:31.014654Z",
          "iopub.status.busy": "2025-07-02T08:22:31.014357Z",
          "iopub.status.idle": "2025-07-02T08:23:03.322611Z",
          "shell.execute_reply": "2025-07-02T08:23:03.321733Z",
          "shell.execute_reply.started": "2025-07-02T08:22:31.014632Z"
        },
        "trusted": true,
        "id": "lGVWKDPsqdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Okukyerererwa kufuuhirira nikyo kirikutokooza ebyokurya ebitwine ebiro ebi.\"\n",
        "my_voice = \"charles\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:39:15.081319Z",
          "iopub.status.busy": "2025-07-02T08:39:15.081047Z",
          "iopub.status.idle": "2025-07-02T08:39:47.636636Z",
          "shell.execute_reply": "2025-07-02T08:39:47.635790Z",
          "shell.execute_reply.started": "2025-07-02T08:39:15.081298Z"
        },
        "trusted": true,
        "id": "Ux7EaxAsqdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Omu disiturikiti ya Kayunga emisiri erikukira obwngi ekashangwa erimu ebicoori ebiine oburwaire.\"\n",
        "my_voice = \"elizabeth\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "kWh_FQyoqdbZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "de3coLAmqdbZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h48o8oNdqdbZ"
      },
      "source": [
        "# Tesso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:35:25.220102Z",
          "iopub.status.busy": "2025-07-03T17:35:25.219780Z",
          "iopub.status.idle": "2025-07-03T17:36:51.888497Z",
          "shell.execute_reply": "2025-07-03T17:36:51.887623Z",
          "shell.execute_reply.started": "2025-07-03T17:35:25.220074Z"
        },
        "trusted": true,
        "id": "AciK5GMlqdbZ"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Uganda-lang/Orpheous-teo-multi-speaker\",\n",
        "    max_seq_length= 2048, # Choose any for long context!\n",
        "    dtype = None, # Select None for auto detection\n",
        "    load_in_4bit = True, # Select True for 4bit which reduces memory usage\n",
        "    token = \"[token]\", # Replace with your token\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-03T17:37:23.441972Z",
          "iopub.status.busy": "2025-07-03T17:37:23.441692Z",
          "iopub.status.idle": "2025-07-03T17:37:59.560981Z",
          "shell.execute_reply": "2025-07-03T17:37:59.560250Z",
          "shell.execute_reply.started": "2025-07-03T17:37:23.441952Z"
        },
        "trusted": true,
        "id": "JuAcJZA_qdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Epedorete akoriok aimedaun ejok kanejaas aicoreta nu itikitikere adeka.\"\n",
        "my_voice = \"christopher\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "eLXMNGz3qdbZ"
      },
      "outputs": [],
      "source": [
        "# Supported voices:\n",
        "# Mitchelle\n",
        "# Barbara\n",
        "# Jessica\n",
        "# Christopher\n",
        "# James\n",
        "# Daniel\n",
        "# Charles\n",
        "# Mark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:55:52.839510Z",
          "iopub.status.busy": "2025-07-02T08:55:52.838757Z",
          "iopub.status.idle": "2025-07-02T08:56:11.071139Z",
          "shell.execute_reply": "2025-07-02T08:56:11.070508Z",
          "shell.execute_reply.started": "2025-07-02T08:55:52.839486Z"
        },
        "trusted": true,
        "id": "102VZUu1qdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Akoru ikorion luegelegela nes ingarakini itunganan.\"\n",
        "my_voice = \"jessica\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:57:12.998785Z",
          "iopub.status.busy": "2025-07-02T08:57:12.998482Z",
          "iopub.status.idle": "2025-07-02T08:57:32.544422Z",
          "shell.execute_reply": "2025-07-02T08:57:32.543780Z",
          "shell.execute_reply.started": "2025-07-02T08:57:12.998763Z"
        },
        "trusted": true,
        "id": "_lxkTRUyqdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Iraasit yen emunaara aticepak ikur enyamitos.\"\n",
        "my_voice = \"james\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T08:59:51.059029Z",
          "iopub.status.busy": "2025-07-02T08:59:51.058381Z",
          "iopub.status.idle": "2025-07-02T09:00:12.691892Z",
          "shell.execute_reply": "2025-07-02T09:00:12.691146Z",
          "shell.execute_reply.started": "2025-07-02T08:59:51.059007Z"
        },
        "trusted": true,
        "id": "wGMT7hwwqdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Aipagisanar nes ewai ecie lo ibwaikinet iboro toma aswam.\"\n",
        "my_voice = \"daniel\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-02T09:00:32.257572Z",
          "iopub.status.busy": "2025-07-02T09:00:32.257046Z",
          "iopub.status.idle": "2025-07-02T09:00:58.467267Z",
          "shell.execute_reply": "2025-07-02T09:00:58.466550Z",
          "shell.execute_reply.started": "2025-07-02T09:00:32.257522Z"
        },
        "trusted": true,
        "id": "FRnWwu7kqdbZ"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"Isisianakinete isomeroi kwana asiomak eipone lo isubusaere.\"\n",
        "my_voice = \"barbara\"\n",
        "\n",
        "# Call the function to generate and display the audio\n",
        "generate_audio_from_prompt(\n",
        "    prompt=my_prompt,\n",
        "    chosen_voice=my_voice,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    snac_model=snac_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "B9IgV3sYqdbZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "8RDzW73cqdbZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}